# This file was automatically generated by Cerebrium as a starting point for your project. 
# You can edit it as you wish.
# If you would like to learn more about your Cerebrium config, please visit https://docs.cerebrium.ai/cerebrium/environments/config-files#config-file-example

[cerebrium.build]
predict_data = "{\"prompt\": \"Here is some example predict data for your config.yaml which will be used to test your predict function on build.\"}"
hide_public_endpoint = false
disable_animation = false
disable_build_logs = false
disable_syntax_check = false
disable_predict = false
log_level = "INTERNAL"
disable_confirmation = false

[cerebrium.deployment]
name = "lnb-bot3"
python_version = "3.11"
include = "[./*, main.py, cerebrium.toml]"
exclude = "[./example_exclude, requirements.txt, venv, __pycache__, .git]"
# cuda_version = "12"
docker_base_image_url = "registry.cerebrium.ai/daily:latest"

[cerebrium.hardware]
region = "us-east-1"
provider = "aws"
compute = "AMPERE_A10"
cpu = 4
memory = 18.0
gpu_count = 1

[cerebrium.scaling]
min_replicas = 0
max_replicas = 5
cooldown = 180

[cerebrium.dependencies.pip]
torch = "==2.3.0"
"pipecat-ai[silero, daily, openai, deepgram]" = "==0.0.35"
aiohttp = "==3.9.5"
openai = ">=1.26.0"
torchaudio = "==2.3.0"
vllm = "==0.5.0.post1"
huggingface_hub = "==0.23.4"
pydantic = "==2.8.0"
accelerate="==0.31.0"
websocket-client="==1.8.0"
xformers="==0.0.26.post1"
google-auth="==2.23.4"

[cerebrium.dependencies.conda]

[cerebrium.dependencies.apt]
